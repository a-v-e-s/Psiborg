{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, sqlite3, copy\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.dirname(os.path.abspath(filepath))\n",
    "with open(filepath, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "timestamps = []\n",
    "for x in range(len(data)):\n",
    "    for y in data[x].keys():\n",
    "        timestamps.append(y)\n",
    "db = sqlite3.Connection('db.sqlite')\n",
    "curs = db.cursor()\n",
    "tables = curs.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name;\").fetchall()[2:]\n",
    "tables = [x[0] for x in tables]\n",
    "for x in tables:\n",
    "    start_time = curs.execute('SELECT MIN(Timestamp) FROM ' + x + ';').fetchall()[0][0]\n",
    "    if start_time > timestamps[0] and start_time < timestamps[-1]:\n",
    "        table = x\n",
    "        break\n",
    "try:\n",
    "    print('Using table: ' + table)\n",
    "except NameError:\n",
    "    print('Could not find a table with timestamps matching EEG data.')\n",
    "    table = None\n",
    "    curs.close()\n",
    "    db.close()\n",
    "\n",
    "os.chdir(os.path.dirname(filepath))\n",
    "deltas = []\n",
    "thetas = []\n",
    "alphas = []\n",
    "betas = []\n",
    "gammas = []\n",
    "for x in range(len(data)):\n",
    "    for y in data[x].values():\n",
    "        for z in range(len(y[0])):\n",
    "            if z == 0:\n",
    "                deltas.append(y[0][z])\n",
    "            elif z == 1:\n",
    "                thetas.append(y[0][z])\n",
    "            elif z == 2:\n",
    "                alphas.append(y[0][z])\n",
    "            elif z == 3:\n",
    "                betas.append(y[0][z])\n",
    "            elif z == 4:\n",
    "                gammas.append(y[0][z])\n",
    "smooth_deltas = []\n",
    "smooth_thetas = []\n",
    "smooth_alphas = []\n",
    "smooth_betas = []\n",
    "smooth_gammas = []\n",
    "for x in range(len(data)):\n",
    "    for y in data[x].values():\n",
    "        for z in range(len(y[1])):\n",
    "            if z == 0:\n",
    "                smooth_deltas.append(y[1][z])\n",
    "            elif z == 1:\n",
    "                smooth_thetas.append(y[1][z])\n",
    "            elif z == 2:\n",
    "                smooth_alphas.append(y[1][z])\n",
    "            elif z == 3:\n",
    "                smooth_betas.append(y[1][z])\n",
    "            elif z == 4:\n",
    "                smooth_gammas.append(y[1][z])\n",
    "# Alpha Protocol:\n",
    "# Simple redout of alpha power, divided by delta waves in order to rule out noise\n",
    "alpha_over_delta = []\n",
    "# Beta Protocol:\n",
    "# Beta waves have been used as a measure of mental activity and concentration\n",
    "# This beta over theta ratio is commonly used as neurofeedback for ADHD\n",
    "beta_over_theta = []\n",
    "# Alpha/Theta Protocol:\n",
    "# This is another popular neurofeedback metric for stress reduction\n",
    "# Higher theta over alpha is supposedly associated with reduced anxiety\n",
    "theta_over_alpha = []\n",
    "# Gamma/Beta:\n",
    "# I suspect this may indicate when a person's intuition is at its strongest.\n",
    "# Gamma waves have been associated with psi phenomena by multiple other researchers.\n",
    "# Beta brainwaves are associated with analytical thinking, which is widely believed to inhibit psi.\n",
    "gamma_over_beta = []\n",
    "# here we go!\n",
    "for x in range(len(smooth_deltas)):\n",
    "    alpha_over_delta.append(smooth_alphas[x] / smooth_deltas[x])\n",
    "    beta_over_theta.append(smooth_betas[x] / smooth_thetas[x])\n",
    "    theta_over_alpha.append(smooth_thetas[x] / smooth_alphas[x])\n",
    "    gamma_over_beta.append(smooth_gammas[x] / smooth_betas[x])\n",
    "if table is not None:\n",
    "    corrects = curs.execute('select timestamp from ' + table + ' where Correct=1;').fetchall()\n",
    "    incorrects = curs.execute('select timestamp from ' + table + ' where Correct=0;').fetchall()\n",
    "    stamps = curs.execute('select timestamp from ' + table + ' where Correct=0 or Correct=1;').fetchall()\n",
    "else:\n",
    "    stamps, corrects, incorrects = None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_deltas, avg_thetas, avg_alphas, avg_betas, avg_gammas = [], [], [], [], []\n",
    "avg_smooth_deltas, avg_smooth_thetas, avg_smooth_alphas, avg_smooth_betas, avg_smooth_gammas = [], [], [], [], []\n",
    "avg_alpha_over_delta, avg_beta_over_theta, avg_theta_over_alpha, avg_gamma_over_beta = [], [], [], []\n",
    "\n",
    "disposable = copy.deepcopy(data)\n",
    "t = stamps.pop(0)[0]\n",
    "raws, avgs, ratios = [], [], []\n",
    "for x in range(len(disposable)):\n",
    "    if disposable[x].popitem()[0] >= t:\n",
    "        # stuff\n",
    "        delts, thets, alphs, bets, gamms = [], [], [], [], []\n",
    "        for y in range(len(raws)):\n",
    "            delts.append(raws[x][0])\n",
    "            thets.append(raws[x][1])\n",
    "            alphs.append(raws[x][2])\n",
    "            bets.append(raws[x][3])\n",
    "            gamms.append(raws[x][4])\n",
    "        avg_deltas.append(stats.mean(delts))\n",
    "        avg_thetas.append(stats.mean(thets))\n",
    "        avg_alphas.append(stats.mean(alphs))\n",
    "        avg_betas.append(stats.mean(bets))\n",
    "        avg_gammas.append(stats.mean(gamms))\n",
    "        #\n",
    "        s_delts, s_thets, s_alphs, s_bets, s_gamms = [], [], [], [], []\n",
    "        for y in range(len(avgs)):\n",
    "            s_delts.append(avgs[x][0])\n",
    "            s_thets.append(avgs[x][1])\n",
    "            s_alphs.append(avgs[x][2])\n",
    "            s_bets.append(avgs[x][3])\n",
    "            s_gamms.append(avgs[x][4])\n",
    "        avg_smooth_deltas.append(stats.mean(s_delts))\n",
    "        avg_smooth_thetas.append(stats.mean(s_thets))\n",
    "        avg_smooth_alphas.append(stats.mean(s_alphs))\n",
    "        avg_smooth_betas.append(stats.mean(s_bets))\n",
    "        avg_smooth_gammas.append(stats.mean(s_gamms))\n",
    "        #\n",
    "        alph_delt, bet_thet, thet_alph, gamm_bet = [], [], [], []\n",
    "        for y in range(len(ratios)):\n",
    "            alph_delt.append(ratios[y][0])\n",
    "            bet_thet.append(ratios[y][1])\n",
    "            thet_alph.append(ratios[y][2])\n",
    "            gamm_bet.append(ratios[y][3])\n",
    "        avg_alpha_over_delta.append(stats.mean(alph_delt))\n",
    "        avg_beta_over_theta.append(stats.mean(bet_thet))\n",
    "        avg_theta_over_alpha.append(stats.mean(thet_alph))\n",
    "        avg_gamma_over_beta.append(stats.mean(gamm_bet))\n",
    "        #\n",
    "        raws, avgs, ratios = [], [], []\n",
    "        try:\n",
    "            t = stamps.pop(0)[0]\n",
    "            continue\n",
    "        except IndexError:\n",
    "            break\n",
    "    raws.append([\n",
    "        deltas[x],\n",
    "        thetas[x],\n",
    "        alphas[x],\n",
    "        betas[x],\n",
    "        gammas[x]\n",
    "    ])\n",
    "    avgs.append([\n",
    "        smooth_deltas[x],\n",
    "        smooth_thetas[x],\n",
    "        smooth_alphas[x],\n",
    "        smooth_betas[x],\n",
    "        smooth_gammas[x]\n",
    "    ])\n",
    "    ratios.append([\n",
    "        alpha_over_delta[x],\n",
    "        beta_over_theta[x],\n",
    "        theta_over_alpha[x],\n",
    "        gamma_over_beta[x]\n",
    "    ])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}